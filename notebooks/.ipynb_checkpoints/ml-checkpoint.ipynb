{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/preprocessed_credit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112633, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"person_90_days_past\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"person_90_days_past\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regression needs standarized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit the model with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train_std, y_train)\n",
    "y_pred = model.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a classifier that distinguishes if a borrower will have a 90 days past due or worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     10639\n",
      "           1       0.55      0.10      0.17       625\n",
      "\n",
      "    accuracy                           0.95     11264\n",
      "   macro avg       0.75      0.55      0.57     11264\n",
      "weighted avg       0.93      0.95      0.93     11264\n",
      "\n",
      "Confusion Matrix: \n",
      "[[10587    52]\n",
      " [  561    64]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classification Report: \\n{classification_report(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Under ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict_proba(X_test_std)\n",
    "y_pred_prob = [p[1] for p in y_pred_prob]\n",
    "print(f\"Score = {np.round(roc_auc_score(y_test, y_pred_prob), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(model, X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's use parameter class_weight that should help more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "model_1.fit(X_train_std, y_train)\n",
    "y_pred_1 = model_1.predict(X_test_std)\n",
    "print(f\"Classification Report: \\n{classification_report(y_test, y_pred_1)}\\n\")\n",
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_pred_1)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Under ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_1 = model_1.predict_proba(X_test_std)\n",
    "y_pred_prob_1 = [p[1] for p in y_pred_prob_1]\n",
    "print(f\"Score = {np.round(roc_auc_score(y_test, y_pred_prob_1), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(model_1, X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The number of Type II errors decreased but increased a lot the type I errors\n",
    "- It seems we need to move on to something different. We cannot see a notable improvement\n",
    "- In fact, the model is worse than previous\n",
    "- Let's implement ***class_weight*** manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['person_90_days_past'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {0 : '0.945052', 1 : '0.054948'}\n",
    "model_2 = LogisticRegression(class_weight=weights, solver='liblinear')\n",
    "model_2.fit(X_train_std, y_train)\n",
    "y_pred_2 = model_2.predict(X_test_std)\n",
    "print(f\"Classification Report: \\n{classification_report(y_test, y_pred_2)}\\n\")\n",
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_pred_2)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we had an improvement over errors type 1 (FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under ROC curve\n",
    "y_pred_prob_2 = model_2.predict_proba(X_test_std)\n",
    "y_pred_prob_2 = [p[1] for p in y_pred_prob_2]\n",
    "print(f\"Score = {np.round(roc_auc_score(y_test, y_pred_prob_2), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(model_2, X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Another Improvements:\n",
    "    - One improvement would be to do a GridSearch over weights params.\n",
    "    - Another method could be up(down)sampling. As the problem with our data set, is that algorithms see drastically more negative (zero) cases than positive during the training stage, and it makes the models less accurate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
